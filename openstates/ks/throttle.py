import functools
import scrapelib
import time


'''
Adapted from wrapper in openstates/openstates/ny/apiclient.py
'''


def check_response(method):
    """
    Decorated functions will run, and if they come back with a 429
    and retry-after header, will wait and try again.

    Args:
        method: the method to wrap
    """
    @functools.wraps(method)
    def wrapped(self, *args, **kwargs):
        try:
            response = method(self, *args, **kwargs)
        except scrapelib.HTTPError as e:
            if e.response.status_code == 429:
                self.handle_429(e.response)
                return method(self, *args, **kwargs).json()
            raise e

        return response.json()

    return wrapped


class ThrottleWrapper(object):

    def __init__(self, scraper):
        self.scraper = scraper

    @check_response
    def get(self, url):
        return self.scraper.get(url)

    def handle_429(self, resp):
        """
        From the kslegislature.org 429 error response:

        'Error 429 You have received this notification because this IP address is querying the kslegislature.org website
         at a high rate.  If the queries are generated by an automated tool, please introduce a delay rate of 3-5
         seconds between queries.  The guide to using a RESTianAPI to access legislative data can be found here:
         http://kslegislature.org/klois/includes/kliss_restian_interface_guide_v10.pdf and please call 785-368-7157
         with additional questions, or email legserv@las.ks.gov'

         Wait time is set to half of the value in the 'Retry-After' header because waiting for the full value in the
         header leads to intermittent ConnectionErrors, possibly because the session keep-alive has expired and an
         attempt is being made to make a request on the same connection. Requests throttled at half of the value
         succeed always.

        Args:
            resp: the response to handle.
        """
        seconds_to_sleep = float(resp.headers['Retry-After']) / 2
        self.scraper.info('Got a 429: Sleeping %s seconds - 50 percent of Retry-After header value.' % seconds_to_sleep)
        time.sleep(seconds_to_sleep)
